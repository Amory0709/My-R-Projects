# Step 0: Load data and Feauture Engineering
```{r}
path = "//rgare.net/stlcommon/ACTURIAL/Global R&D/Predictive Modeling Projects/Project/"
proj_folder = "Indonesia_AIA/RData/"
file_name = "AIA_MOD_DATA_V1.RData"

load(paste(path, proj_folder, file_name, sep = ""))
#1131080

library(funModeling)
library(ggplot2)
#install.packages("rms")
library(rms)

# par(mfrow = c(2,2))

#tweak the data
names(AIA_MOD_DATA)[4]<-'DummyID'
names(AIA_MOD_DATA)[7]<-'PlanOption'
names(AIA_MOD_DATA)[8]<-'RiderType'
names(AIA_MOD_DATA)

#check PlanOption_v2 if can delete
table(AIA_MOD_DATA$PlanOption_v2)
subset(AIA_MOD_DATA,is.na(AIA_MOD_DATA$PlanOption_v2))# 0 rows
subset(AIA_MOD_DATA, AIA_MOD_DATA$PlanOption==AIA_MOD_DATA$PlanOption_v2)# 1051435 

testPlanOption <- subset(AIA_MOD_DATA, AIA_MOD_DATA$PlanOption!=AIA_MOD_DATA$PlanOption_v2)# 79645
table(testPlanOption$PlanOption)
table(testPlanOption$PlanOption_v2)
rm(testPlanOption)

# So we delete PlanOption and keep PlanOption_v2
AIA_MOD_DATA$PlanOption <- NULL
#check
names(AIA_MOD_DATA)
rm(testPlanOpition)

# if delete incurredMonth 
subset(AIA_MOD_DATA, !is.na(AIA_MOD_DATA$IncurredMonth)) #13453
testIncurredMonth <- subset(AIA_MOD_DATA, AIA_MOD_DATA$CalendarMonth==AIA_MOD_DATA$IncurredMonth) #13453
## delete incurredMonth
AIA_MOD_DATA$IncurredMonth <- NULL
rm(testIncurredMonth)

# Check currency
table(AIA_MOD_DATA$Currency)
omitUSD = AIA_MOD_DATA$Currency!='USD'
AIA_noUSD <- subset(AIA_MOD_DATA, omitUSD) # 1126407
AIA_noUSD$Currency <- NULL
rm(AIA_MOD_DATA)
rm(omitUSD)

# check policy type _v3
table(AIA_noUSD$PolicyType)
library(dplyr)
AIA_noUSD$PolicyType <- case_when(
  AIA_noUSD$PolicyType == 'nb'~ 'NB',
  AIA_noUSD$PolicyType == 'NB  '~ 'NB',
  AIA_noUSD$PolicyType == 'ren'~ 'REN',
  AIA_noUSD$PolicyType == 'RN'~ 'REN',
  TRUE ~ as.character(AIA_noUSD$PolicyType)
)
AIA_noUSD$PolicyType <- as.factor(AIA_noUSD$PolicyType)
table(AIA_noUSD$PolicyType)

# delete RINETPrem_IDR
testRINET <- (subset(AIA_noUSD, AIA_noUSD$RINetPrem==AIA_noUSD$RINetPrem_IDR))#1126407
AIA_noUSD$RINetPrem_IDR <- NULL
rm(testRINET)

#change plan
testChangePlan <- subset(AIA_noUSD, is.na(AIA_noUSD$ChangePlanMonth))#1034697
testChangePlan2 <- subset(AIA_noUSD, !is.na(AIA_noUSD$ChangePlanMonth))#91710
AIA_noUSD$changePlanDummy <- ifelse(is.na(AIA_noUSD$ChangePlanMonth),0,1)
rm(testChangePlan)
rm(testChangePlan2)

# alter Deductible_Options
AIA_noUSD$Deductible_Options <- as.factor(AIA_noUSD$Deductible_Options)

# entry age LB
table(AIA_noUSD$AttainedAge_LB)
AIA_noUSD$AttainedAge_LB <- ifelse(AIA_noUSD$AttainedAge_LB>=65, 65, as.integer(AIA_noUSD$AttainedAge_LB))
table(AIA_noUSD$AttainedAge_LB)
AIA_noUSD$AttainedAge_LB<- as.integer(AIA_noUSD$AttainedAge_LB)

#Calendar Year
table(AIA_noUSD$CalendarYear)
# omit 2013
AIA_noUSD <- subset(AIA_noUSD, AIA_noUSD$CalendarYear!= '2013')# 1126023

#Policy Year
table(AIA_noUSD$PolicyYear)
# drop rows where PolicyYear >= 6
AIA_noUSD <- subset(AIA_noUSD, AIA_noUSD$PolicyYear < 6) # 1124884

# Group PolicyProvince
AIA_noUSD$PolicyProvince = as.character(AIA_noUSD$PolicyProvince)
# Group by location
AIA_noUSD$PolicyProvince_v2 <- case_when(
  AIA_noUSD$PolicyProvince %in% c("BALI","NUSA TENGGARA BARAT", "NUSA TENGGARA TIMUR") ~ "BALI",
  AIA_noUSD$PolicyProvince %in% c("BANTEN","JAKARTA") ~ "JAKARTA",
  AIA_noUSD$PolicyProvince %in% c("YOGYAKARTA","JAWA BARAT","JAWA TENGAH","JAWA TIMUR") ~ "JAWA",
  AIA_noUSD$PolicyProvince %in% c("KALIMANTAN BARAT","KALIMANTAN SELATAN","KALIMANTAN TENGAH","KALIMANTAN TIMUR","KALIMANTAN UTARA") ~ "KALIMANTAN",
  AIA_noUSD$PolicyProvince %in% c("MALUKU","MALUKU UTARA") ~ "MALUKU",
  AIA_noUSD$PolicyProvince %in% c("RIAU","SUMATERA UTARA") ~ "NORTH SUMATERA",
  AIA_noUSD$PolicyProvince %in% c("PAPUA","PAPUA BARAT") ~ "PAPUA",
  AIA_noUSD$PolicyProvince %in% c("GORONTALO","SULAWESI BARAT","SULAWESI SELATAN","SULAWESI TENGAH","SULAWESI TENGGARA","SULAWESI UTARA") ~ "SULAWESI",
  AIA_noUSD$PolicyProvince %in% c("ACEH","BANGKA BELITUNG ISLANDS","BENGKULU","JAMBI","LAMPUNG","SUMATERA BARAT","SUMATERA SELATAN","KEPULAUAN RIAU") ~ "SUMATERA",
  AIA_noUSD$PolicyProvince %in% c("UNKNOWN") ~ "OTHERS",
  TRUE ~ as.character(AIA_noUSD$PolicyProvince)
)
AIA_noUSD$PolicyProvince_v2 = as.factor(AIA_noUSD$PolicyProvince_v2)
table(AIA_noUSD$PolicyProvince_v2)

#HI_indicater
table(AIA_noUSD$HI_Indicator)
nrow(subset(AIA_noUSD, is.na(AIA_noUSD$HI_Indicator))) #33107
AIA_noUSD$HI_Indicator_v2 <- ifelse(is.na(AIA_noUSD$HI_Indicator),"NA",as.factor(AIA_noUSD$HI_Indicator))
table(AIA_noUSD$HI_Indicator_v2)
AIA_noUSD$HI_Indicator_v2 <- as.factor(AIA_noUSD$HI_Indicator_v2)

#Preprocess Data
AIA_noUSD$PolicyNo <- as.character(AIA_noUSD$PolicyNo)
AIA_noUSD$CalendarYear <- as.factor(AIA_noUSD$CalendarYear)
AIA_noUSD$PlanOption_v2 <- as.factor(AIA_noUSD$PlanOption_v2)
AIA_noUSD$HI_Indicator <- as.factor(AIA_noUSD$HI_Indicator)


#save(AIA_noUSD, file = 'AIA_MOD_DATA_v3_0717.Rdata')
#write.csv(AIA_noUSD,'AIA_v2.csv')
```

```{r}
#check the restricted cubic spline of AttainedAge_LB
test.fit <- glm(CLAIM_CNT ~ rcs(AttainedAge_LB, c(5, 15, 20, 45, 50)
                                #,include.lowest = TRUE
                                )+
                        offset(log(Exposure)), data = AIA_noUSD, family = poisson(link = "log"))
par(mfrow = c(1,2))
plot(AIA_noUSD$AttainedAge_LB, log(AIA_noUSD$CLAIM_CNT/AIA_noUSD$Exposure))
points(AIA_noUSD$AttainedAge_LB, log(AIA_noUSD$CLAIM_CNT/AIA_noUSD$Exposure))

plot(AIA_noUSD$AttainedAge_LB, test.fit$fitted.values, 
     col = "red", 
     xlim = c(min(AIA_noUSD$AttainedAge_LB), max(AIA_noUSD$AttainedAge_LB)))

```

# Step 1 : Check NA, outliers and skewness
```{r}
df_status(AIA_noUSD)
```
## check the target variable
```{r}
par(mfrow=c(1,2))
hist(AIA_noUSD$CLAIM_CNT)
hist(log(AIA_noUSD$CLAIM_CNT/AIA_noUSD$Exposure)) # NB distribution
table(AIA_noUSD$CLAIM_CNT)
mean(AIA_noUSD$CLAIM_CNT)# 0.02092038
var(AIA_noUSD$CLAIM_CNT)# 0.05954813
# over dispersion
summary(AIA_noUSD$CLAIM_CNT)
```

## check relationship between "CLAIM_CNT" and predictors(in other software)


# Step 2: Split the dataset
```{r}
# 75% of the sample size for training
set.seed(1)
train_id <- sample.int(n = nrow(AIA_noUSD), size = floor(0.75*nrow(AIA_noUSD)), replace = F)
AIA_train <- AIA_noUSD[train_id,] # 843663
AIA_test <- AIA_noUSD[-train_id,] # 281221
```

```{r}
# Step 3: EXtract data for model

#dataProcess <- function(data){
  # select appropriate predictors
 # newdata <- subset(data, select = c(PolicyType, PlanType, RiderType, Gender, RINetPrem,
  #                                   PolicyYear,AttainedAge_LB,Exposure,CalendarYear, Channel, PolicyProvince,
  #                                   Std_SubStd,Deductible_Options,Smoking,HI_Indicator,PlanOption_v2,
  #                                   CLAIM_CNT,changePlanDummy))
  #return(newdata)
#}

#AIA_train <- dataProcess(AIA_train)
#AIA_test <- dataProcess(AIA_test)
```


# Step 3: Build model

## Build glm model
target: claim cnt  
family=poisson  
log link
offset=exposure

Turns out that when we using the original dataset, the results are pretty bad. So we aggregate our data by the feature we have selected and observe if there are any improvement.
```{r}
library(data.table)
setDT(AIA_noUSD)
AIA_SUM =
  AIA_noUSD[,
                        list(
                          Exposure_SUM = sum(Exposure),
                          CLAIM_CNT_SUM = sum(CLAIM_CNT)
                        ),
                        by = list(AttainedAge_LB, Gender ,
                        PolicyType, 
                        #PlanType,
                        RiderType, 
                        #Gender, 
                        RINetPrem,
                        PolicyYear,
                        #AttainedAge_LB,
                        CalendarYear, 
                        Channel, 
                        PolicyProvince_v2,
                        #Deductible_Options,
                        HI_Indicator_v2,
                        #Std_SubStd,
                        #Smoking,
                        PlanOption_v2)]
nrow(AIA_SUM)# 163141 with deductible_options
# 152537
names(AIA_SUM)
#write.csv(AIA_SUM,'AIA_RAW_DATA.csv')
```

## check target distribution
```{r}
hist(AIA_SUM$CLAIM_CNT_SUM)
hist(log(AIA_SUM$CLAIM_CNT_SUM/AIA_SUM$Exposure_SUM))

```

## split data
```{r}
# 75% of the sample size for training
set.seed(1)
train_id <- sample.int(n = nrow(AIA_SUM), size = floor(0.75*nrow(AIA_SUM)), replace = F)
AIA_train <- AIA_SUM[train_id,] # 122355  with deductible_options
#114402
AIA_test <- AIA_SUM[-train_id,] # 40786  with deductible_options
#38135
```


## fit the model to test the performance
```{r}
AIA.fit <- glm(CLAIM_CNT_SUM ~ 
                        rcs(AttainedAge_LB, c(5, 15, 20, 45, 50)): Gender +
                        PolicyType+ 
                        #PlanType+
                        RiderType+ 
                        #Gender+ 
                        RINetPrem+
                        PolicyYear+
                        #AttainedAge_LB+
                        CalendarYear+ 
                        Channel+ 
                        PolicyProvince_v2+
                        #Deductible_Options+
                        HI_Indicator_v2+
                        #Std_SubStd+
                        #Smoking+
                        PlanOption_v2+
                        offset(log(Exposure_SUM)), data = AIA_train, family = poisson(link = "log"))
summary(AIA.fit)

```

```{r}
AIA_train$fitted.Value <- AIA.fit$fitted.values

#check train data MSE
mean((AIA.fit$fitted.values-AIA_train$CLAIM_CNT_SUM)^2)#  0.7473741 with deductible_options
# 0.8458295
```

```{r}
# check predict data MSE
AIA_test$Prediction <- predict(AIA.fit, newdata = AIA_test, type = "response")
mean((AIA_test$Prediction - AIA_test$CLAIM_CNT_SUM)^2) #  0.7874016 with deductible_options
# 0.760566
```

## Step 4: cross validation
```{r}
cross_validation = function(nbr_cv, nbr_folds, m_dat2)
{
  # define matrices to hold test predictions
  fullM = matrix(NA, nrow = nrow(m_dat2), ncol = length(nbr_cv))
  j = 1
  for (seed in nbr_cv)
  { 
    # repeat the cross validation with diffrent random seeds
    # cat("\n\ncross validation nbr: ", j, "\n\n")
    
    # random partition
    set.seed(seed)
    fold = sample(1:nbr_folds, size = nrow(m_dat2), replace = TRUE)
    
    for (i in seq_len(nbr_folds))
    {
      cat("Fold   ", i, "\n\n")
      test = which(fold == i)
      train = (-test)
      
      # fit models
      glmAllCV = glm(
        CLAIM_CNT_SUM ~ 
                        rcs(AttainedAge_LB, c(5, 15, 20, 45, 50)): Gender +
                        PolicyType+ 
                        #PlanType+
                        RiderType+ 
                        #Gender+ 
                        RINetPrem+
                        PolicyYear+
                        #AttainedAge_LB+
                        CalendarYear+ 
                        Channel+ 
                        PolicyProvince_v2+
                        #Deductible_Options+
                        HI_Indicator_v2+
                        #Std_SubStd+
                        #Smoking+
                        PlanOption_v2+
                        offset(log(Exposure_SUM)), 
                        data = m_dat2[train, ], 
                        family = poisson(link = "log")ï¼Œ
                        control = list(maxit = 1000)
      )
      # predictions
      # cat("Finish ", i, " train\n\n")
      prediction <- predict(glmAllCV, newdata = m_dat2[test, ], type = "response")
     
      fullM[test, j]  = predict(glmAllCV, newdata = m_dat2[test, ], type = "response")
      # cat("Finish ", i, " fullM\n\n")
    }
    
    j = j + 1
  }
  #cat("Result", fullM)
  m_dat2 = cbind(m_dat2, fullM)
  
  return(m_dat2)
}

CV_RESULT = cross_validation(c(1), 10, AIA_SUM)
CV_RESULT$PREDICT = CV_RESULT$V1
```
## Step 5: lift curve
```{r}
# Lift curve
kBin = 10
nrows = dim(CV_RESULT)[1]
splitIndex = (1:nrows) %% kBin
splitFactor = factor(splitIndex[order(splitIndex)])

# Lift Curve on full model
CV_RESULT$ordered = 0
CV_RESULT$ordered[order(CV_RESULT$PREDICT / CV_RESULT$Exposure)] = splitFactor

#================ A = ACT_IBNR_AMT_UNIT, E = EXPECT_AMT_UNIT ================#
setDT(CV_RESULT)
byDecile = CV_RESULT[,
                          list(
                            CLAIM_CNT_SUM=sum(CLAIM_CNT_SUM),
                            PREDICT = sum(PREDICT),
                            EXPOSURE = sum(Exposure_SUM),
                            RINetPrem = sum(RINetPrem)
                          ),
                          by = ordered]
byDecile = cbind(byDecile, AoE = byDecile$PREDICT / byDecile$EXPOSURE)
byDecile = byDecile[order(byDecile$ordered)]

write.csv(byDecile, file = 'Lift.csv')

DecileBar =
  barplot(
    byDecile$AoE,
    names.arg = 1:kBin,
    cex.names = 0.9,
    main = paste0("Lift Curve of Cross Validation"),
    ylim = c(0, 1.25 * max(byDecile$AoE)),
    xlab = "Decile"
  )
abline(
  sum(CV_RESULT$CLAIM_CNT_SUM) / sum(CV_RESULT$Exposure),
  0,
  col = "red"
)
```
To sum up, the average incident rate is around 25%.
